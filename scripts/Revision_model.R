#----------------------------------------------------------------------------------------------------------------------------------#
# Script by: Lucien Fitzpatrick
# Project: Collection phenology vulnerability
# Purpose: This script fits the spatial bias model 
# Inputs: Budburst data frame with residuals created by script 9
#         Leaf out data frame with residuals created by script 9 
# Outputs: Model output of fit bias correction
# Notes: 
#-----------------------------------------------------------------------------------------------------------------------------------#
library(rjags)
library(coda)
library(dplyr)
library(tidyr)
#reading in the budburst dataframe with residuals
#Reading in our cleaned NPN data
#Reading in the npn data we are going to predict
dat.burst <- read.csv("../data_raw/Raw_Phenology_NPN_combined_budburst.csv")
dat.burst <- dat.burst[!is.na(dat.burst$Yday),]
dat.burst <- dat.burst[!is.infinite(dat.burst$Yday),]

#Putting a filter on reports after August 1st since we are interested in spring phenology
dat.burst <- dat.burst[dat.burst$Yday < 213,]

dat.burst$Date <- as.Date(dat.burst$Date)
dat.burst$species <- as.character(dat.burst$species)


#reading in the leafout dataframe with residuals
dat.leaf <- read.csv("../data_raw/Raw_Phenology_NPN_combined_leaf.csv")
dat.leaf <- dat.leaf[!is.na(dat.leaf$Yday),]
dat.leaf <- dat.leaf[!is.infinite(dat.leaf$Yday),]

dat.leaf <- dat.leaf[dat.leaf$Yday < 213,]

dat.leaf$species <- as.character(dat.leaf$species)



#Reading in the weather data
dat.met <- read.csv("../data_processed/Daymet_clean_data.csv")
dat.met$Freeze <- ifelse(dat.met$tmin..deg.c.<0, 1, 0)
dat.met$site <- as.character(dat.met$site)

dat.burst$Date <- as.Date(dat.burst$Date)
dat.leaf$Date <- as.Date(dat.leaf$Date)
dat.met$Date <- as.Date(dat.met$Date)


#Calculting the number of sites so we can filter for our second step of evaluation
for(SP in unique(dat.burst$species)){
  dat.sp <- dat.burst[dat.burst$species == SP,]
  dat.burst[dat.burst$species == SP, "nsites"] <- length(unique(dat.sp$site_id))
}

dat.burst <- dat.burst[dat.burst$nsites > 10,]


#Calculting the number of sites so we can filter for our second step of evaluation
for(SP in unique(dat.leaf$species)){
  dat.sp <- dat.leaf[dat.leaf$species == SP,]
  dat.leaf[dat.leaf$species == SP, "nsites"] <- length(unique(dat.sp$site_id))
}

dat.leaf <- dat.leaf[dat.leaf$nsites > 10,]


dat.npnbud <- merge(dat.burst, dat.met, by.x = c("year", "Yday", "site_id"), by.y = c("year", "yday", "site"))
dat.npnbud <- subset(dat.npnbud, select = c("genus", "species", "GDD5.cum", "year", "Yday", "individual_id", "site_id", "latitude.x", "longitude.x"))
colnames(dat.npnbud) <- c("Genus", "Species", "GDD5.cum", "Year", "Yday", "PlantNumber", "Site", "Latitude", "Longitude")
dat.npnbud$Source <- "npn" 
 
dat.npnleaf <- merge(dat.leaf, dat.met, by.x = c("year", "Yday", "site_id"), by.y = c("year", "yday", "site"))
dat.npnleaf <- subset(dat.npnleaf, select = c("genus", "species", "GDD5.cum", "year", "Yday", "individual_id", "site_id", "latitude.x", "longitude.x"))
colnames(dat.npnleaf) <- c("Genus", "Species", "GDD5.cum", "Year", "Yday", "PlantNumber", "Site", "Latitude", "Longitude")
dat.npnleaf$Source <- "npn"


# Read in output of previous script
dat.b <- read.csv("../data_processed/Oak_collection_budburst.csv")
dat.b$Accession <- unlist(lapply(strsplit(paste(dat.b$PlantNumber), "-"), function(x){x[1]}))
dat.b$Date <- as.Date(dat.b$Date)

dat.b <- dat.b %>%
  separate(Species, c("Genus", "Species"), " ")

dat.arbb <- subset(dat.b, select = c("Genus", "Species", "GDD5.cum", "Year", "Yday", "PlantNumber", "Site", "Latitude", "Longitude"))
dat.arbb$Source <- "arb"

# Read in output of previous script
dat.l <- read.csv("../data_processed/Oak_collection_leaf.csv")
dat.l$Accession <- unlist(lapply(strsplit(paste(dat.l$PlantNumber), "-"), function(x){x[1]}))
dat.l$Date <- as.Date(dat.l$Date)
dat.l <- dat.l %>%
  separate(Species, c("Genus", "Species"), " ")

dat.arbl <- subset(dat.l, select = c("Genus", "Species", "GDD5.cum", "Year", "Yday", "PlantNumber", "Site", "Latitude", "Longitude"))
dat.arbl$Source <- "arb"

dat.budcomb <- rbind(dat.npnbud, dat.arbb)
dat.leafcomb <- rbind(dat.npnleaf, dat.arbl)

write.csv(dat.budcomb, "../data_processed/Full_Bud_Obs.csv", row.names = F)
write.csv(dat.leafcomb, "../data_processed/Full_Leaf_Obs.csv", row.names = F)

#Creating indexes so the hierarchy can properly function
burst.ind <- aggregate(Site~PlantNumber, data=dat.budcomb,
                       FUN=min)

burst.loc <- aggregate(Species~PlantNumber, data=dat.budcomb,
                       FUN=min)


leaf.ind <- aggregate(Site~PlantNumber, data=dat.leafcomb,
                       FUN=min)

leaf.loc <- aggregate(Species~PlantNumber, data=dat.leafcomb,
                       FUN=min)

#Actual spatial bias correction model
spatial_correction <- "
  model{
    for(k in 1:n){
        mu[k] <- ind.sp[pln[k]] + (ind.loc[pln[k]] * GT[k])   
        y[k] ~ dnorm(mu[k], sPrec)
    }

      bias.loc <- x
      x ~ dnorm(0, xPrec)
      xPrec ~ dgamma(0.1, 0.1)

    for(t in 1:nSp){
      Sp.bias[t] <-   b[t]
      b[t] ~ dnorm(0, bPrec[t])
      bPrec[t] ~ dgamma(0.1, 0.1)
    }
    
     for(t in 1:nLoc){
      Site[t] <-  bias.loc
      #c[t] ~ dnorm(0, cPrec[t])
      #cPrec[t] ~ dgamma(0.1, 0.1)
    }
    
    for(i in 1:nPln){
        ind.sp[i] <-   Sp.bias[sp[i]] + d.sp[i]
        ind.loc[i] <- Site[loc[i]]
        d.sp[i] ~ dnorm(0, dPrec.sp)
    }
    sPrec ~ dgamma(0.1, 0.1)
    dPrec.sp ~ dgamma(0.1, 0.1)
  }
  "
#Populating the lists with the data needed to run the model
burst.list <- list(y = dat.budcomb$GDD5.cum, n = length(dat.budcomb$GDD5.cum), GT = dat.budcomb$Latitude,
                   pln = as.numeric(factor(dat.budcomb$PlantNumber)), nPln = length(unique(dat.budcomb$PlantNumber)),
                   loc = as.numeric(factor(burst.ind$Site)), nLoc = length(unique(dat.budcomb$Site)),
                   sp = as.numeric(factor(burst.loc$Species)), nSp = length(unique(dat.budcomb$Species)))

#Populating the lists with the data needed to run the model
leaf.list <- list(y = dat.leafcomb$GDD5.cum, n = length(dat.leafcomb$GDD5.cum), GT = dat.leafcomb$Latitude,
                  pln = as.numeric(factor(dat.leafcomb$PlantNumber)), nPln = length(unique(dat.leafcomb$PlantNumber)),
                  loc = as.numeric(factor(leaf.ind$Site)), nLoc = length(unique(dat.leafcomb$Site)),
                  sp = as.numeric(factor(leaf.loc$Species)), nSp = length(unique(dat.leafcomb$Species)))

burst.model   <- jags.model (file = textConnection(spatial_correction),
                             data = burst.list,
                             n.chains = 3)

leaf.model   <- jags.model (file = textConnection(spatial_correction),
                            data = leaf.list,
                            n.chains = 3)


#Converting the ooutput into a workable format
burst.out   <- coda.samples (model = burst.model,
                             variable.names = c("Sp.bias", "bias.loc", "bPrec", "xPrec"),
                             n.iter = 600000)

#Converting the ooutput into a workable format
leaf.out   <- coda.samples (model = leaf.model,
                            variable.names = c("bias.sp", "bias.loc", "aPrec", "xPrec"),
                            n.iter = 600000)


#Checking that convergence happened
gelman.diag(burst.out)

gelman.diag(leaf.out)


#Removing burnin before convergence occurred
burnin = 590000                                ## determine convergence from GBR output
burst.burn <- window(burst.out,start=burnin)  ## remove burn-in
summary(burst.burn)

leaf.burn <- window(leaf.out, start = burnin)
summary(leaf.burn)

#converting them into a dataframe 
burst.df <- as.data.frame(as.matrix(burst.burn))
leaf.df <- as.data.frame(as.matrix(leaf.burn))
summary(burst.df)

summary(leaf.df)


write.csv(burst.df, file.path("../data_processed/model_output/Revision_model_budburst.csv"), row.names=F)
write.csv(leaf.df, file.path("../data_processed/model_output/Revision_model_leaf.csv"), row.names=F)
